# RAPIDS Dockerfile for CentOS7
#
# This multi-stage Dockerfile is used to create three images: devel, runtime,
# and base
#
# devel: RAPIDS is built from-source and installed in the 'rapids' conda
# environment. The sources and toolchains to build RAPIDS are included in this
# image. RAPIDS jupyter notebooks are also provided, as well as jupyterlab and
# all the dependencies required to run them.
#
# runtime: RAPIDS is installed from published conda packages to the 'rapids'
# conda environment. RAPIDS jupyter notebooks are also provided, as well as
# jupyterlab and all the dependencies required to run them.
#
# base: RAPIDS is installed from published conda packages to the 'rapids' conda
# environment.
#
# Copyright (c) 2019, NVIDIA CORPORATION.

# These ARGs are used in multiple stages and must be defined prior to first FROM

ARG CUDA_VERSION=9.2
ARG CUDA_MAJORMINOR_VERSION=${CUDA_VERSION}
ARG LINUX_VERSION=centos7

runcommand ../../commands/utils/dumpDockerArgsFromConfig.sh

################################################################################
# Use the devel image since a CC compiler is needed for the build_gcc7 steps
FROM nvidia/cuda:${CUDA_VERSION}-devel-${LINUX_VERSION} AS rapids_gcc7
ARG GCC7_DIR=/rapids/gcc7

RUN yum upgrade -y && \
    yum install -y \
      wget \
      make \
      file \
      gmp-devel \
      libmpc-devel \
      mpfr-devel \
      texinfo

RUN mkdir -p ${GCC7_DIR} && \
    cd ${GCC7_DIR} && \
    wget -q http://ftp.gnu.org/gnu/gcc/gcc-7.3.0/gcc-7.3.0.tar.gz -O - | tar -xz && \
    cd gcc-7.3.0 && \
    ./configure --prefix=${GCC7_DIR} --disable-multilib && \
    make -j && \
    make install && \
    rm -rf "${GCC7_DIR}/gcc-7.3.0"


################################################################################
# Use the devel image since a CC compiler is needed for the build_gcc7 steps
FROM nvidia/cuda:${CUDA_VERSION}-devel-${LINUX_VERSION} AS rapids_ready

ARG TINI_URL
ARG MINICONDA_URL
ARG CUDA_MAJORMINOR_VERSION
ARG UTILS_DIR=utils
ARG SUPPORT_FILES_DIR=supportfiles

# Add /usr/local/cuda/* temporarily to LD_LIBRARY_PATH to support various build steps
# This will need to be removed later since it causes problems with certain runtime libs (numba.cuda)
ENV LD_LIBRARY_PATH_POSTBUILD=$LD_LIBRARY_PATH
ENV LD_LIBRARY_PATH=$LD_LIBRARY_PATH_POSTBUILD:/usr/local/cuda/lib64:/usr/local/cuda/lib64/stubs
ENV NUMBAPRO_NVVM=/usr/local/cuda/nvvm/lib64/libnvvm.so
ENV NUMBAPRO_LIBDEVICE=/usr/local/cuda/nvvm/libdevice
ENV PATH=$PATH:/conda/bin
ENV CUDA_VERSION=${CUDA_MAJORMINOR_VERSION}
ENV RAPIDS_DIR=/rapids

# devtoolset-7 ENV vars
# devtoolset-7-* packages will need to be seen first, update PATH accordingly
# NOTE: These are commented out since gcc is being built from source
#   If devtoolset-7 is used, uncomment these vars.
# ENV PATH=/opt/rh/devtoolset-7/root/usr/bin:$PATH:/conda/bin
# ENV CC=/opt/rh/devtoolset-7/root/usr/bin/gcc
# ENV CXX=/opt/rh/devtoolset-7/root/usr/bin/g++
# ENV CUDAHOSTCXX=/opt/rh/devtoolset-7/root/usr/bin/g++
RUN mkdir -p ${RAPIDS_DIR}/tmp
#
# The support dir contains RPMs that enable additional repos needed
# for CentOS (among other things). Copy them to a temp dir and remove
# after installed.
#
COPY ${SUPPORT_FILES_DIR}/*.rpm ${RAPIDS_DIR}/tmp

RUN yum install -y ${RAPIDS_DIR}/tmp/*.rpm && \
    yum upgrade -y && \
    yum install -y \
      bzip2 \
      curl \
      git \
      screen \
      vim \
      wget \
      which \
      clang \
      make \
      libnccl-2.4.2-1+cuda${CUDA_MAJORMINOR_VERSION} \
      libnccl-devel-2.4.2-1+cuda${CUDA_MAJORMINOR_VERSION} \
      libnccl-static-2.4.2-1+cuda${CUDA_MAJORMINOR_VERSION} \
      gmp-devel mpfr-devel libmpc-devel file

RUN curl -L ${TINI_URL} -o /usr/bin/tini && \
    chmod +x /usr/bin/tini

RUN rm -rf ${RAPIDS_DIR}/tmp

RUN curl ${MINICONDA_URL} -o /miniconda.sh && \
    sh /miniconda.sh -b -p /conda && \
    conda update -n base conda && \
    rm -f /miniconda.sh

# Enables "source activate conda"
SHELL ["/bin/bash", "-c"]

RUN mkdir -p ${RAPIDS_DIR}
COPY rapids ${RAPIDS_DIR}
COPY utils ${RAPIDS_DIR}/${UTILS_DIR}
# Add test file for testing from within the container
COPY ${SUPPORT_FILES_DIR}/test.sh /test.sh

WORKDIR ${RAPIDS_DIR}

# Automatically active conda env
RUN echo "source activate rapids" > ~/.bashrc

ENTRYPOINT [ "/usr/bin/tini", "--" ]
CMD [ "/bin/bash" ]


################################################################################
# No optimization done yet. Just trying to get functionality in first and then make things cleaner/faster/better
FROM rapids_ready AS devel

# Retrieve values set prior to first FROM command for use below
ARG CC_VERSION
ARG CXX_VERSION
ARG CUDA_VERSION
ARG CUDA_MAJORMINOR_VERSION
ARG RAPIDSAI_CONDA_LABEL
ARG NVIDIA_CONDA_LABEL
ARG PYARROW_VERSION
ARG CFFI_VERSION
ARG CMAKE_VERSION
ARG CYTHON_VERSION
ARG DASK_VERSION
ARG DISTRIBUTED_VERSION
ARG FAISSGPU_VERSION
ARG IPYTHON_VERSION
ARG NUMBA_VERSION
ARG NUMPY_VERSION
ARG PANDAS_VERSION
ARG PYTHON_VERSION
ARG RAPIDSAI_NIGHTLY_CONDA_LABEL
ARG GCC7_DIR=/rapids/gcc7

# Add /usr/local/cuda/* temporarily to LD_LIBRARY_PATH to support various build steps
# This will need to be removed later since it causes problems with certain runtime libs (numba.cuda)
ENV LD_LIBRARY_PATH_POSTBUILD=${LD_LIBRARY_PATH}
ENV LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/local/cuda/lib64:/usr/local/cuda/lib64/stubs
ENV NUMBAPRO_NVVM=/usr/local/cuda/nvvm/lib64/libnvvm.so
ENV NUMBAPRO_LIBDEVICE=/usr/local/cuda/nvvm/libdevice
ENV PATH="${PATH}:/conda/bin"
ENV CUDA_VERSION=${CUDA_MAJORMINOR_VERSION}

# Copy gcc7 binaries and Update environment to use new gcc7
COPY --from=rapids_gcc7 ${GCC7_DIR} ${GCC7_DIR}
ENV CC=${GCC7_DIR}/bin/gcc
ENV CXX=${GCC7_DIR}/bin/g++
ENV PATH=${GCC7_DIR}/bin:$PATH
ENV CUDAHOSTCXX=${GCC7_DIR}/bin/g++

# Update the current LD_LIBRARY_PATH with the new lib64 dir for
# remaining build steps and LD_LIBRARY_PATH_POSTBUILD for runtime use
# after building the container.
ENV LD_LIBRARY_PATH=${GCC7_DIR}/lib64:$LD_LIBRARY_PATH

# conda environment
# NOTE: use these mirrors for faster downloads
#       -c http://10.33.227.188:88/numba \
#       -c http://10.33.227.188:88/conda-forge \
RUN export CUDA_MAJOR=`echo $CUDA_VERSION | cut -d'.' -f1` && \
    export CUDA_MINOR=`echo $CUDA_VERSION | cut -d'.' -f2` && \
    conda create -n rapids python=${PYTHON_VERSION} && \
    conda install -n rapids -y \
      -c ${RAPIDSAI_CONDA_LABEL} \
      -c ${RAPIDSAI_NIGHTLY_CONDA_LABEL} \
      -c ${NVIDIA_CONDA_LABEL} \
      -c nvidia \
      -c numba \
      -c conda-forge \
      -c pytorch \
      -c defaults \
      -c rapidsai \
      arrow-cpp=${PYARROW_VERSION} \
      bokeh \
      cffi=${CFFI_VERSION} \
      cmake=${CMAKE_VERSION} \
      cmake_setuptools">=0.1.3" \
      cuda${CUDA_MAJOR}${CUDA_MINOR} \
      cudatoolkit=${CUDA_MAJORMINOR_VERSION} \
      cython=${CYTHON_VERSION} \
      dask=${DASK_VERSION} \
      distributed=${DISTRIBUTED_VERSION} \
      faiss-gpu=${FAISSGPU_VERSION} \
      ipython=${IPYTHON_VERSION} \
      jupyterlab \
      libclang \
      matplotlib \
      networkx \
      numba=${NUMBA_VERSION} \
      numpy=${NUMPY_VERSION} \
      nccl=2.* \
      openblas \
      pandas=${PANDAS_VERSION} \
      pyarrow=${PYARROW_VERSION} \
      pytest \
      scikit-learn \
      scipy \
      seaborn \
    && conda clean -a

# Special case: libcumlmg is not available for CUDA 9.2
RUN if [ "${CUDA_MAJORMINOR_VERSION}" != "9.2" ]; then conda install -n rapids -y --no-deps -c ${NVIDIA_CONDA_LABEL} -c conda-forge libcumlmg; fi

# clone.sh is generated by `rapidsdevtool.sh buildDockerImage` and is based on
# the URLs and branch names in the config file.
RUN cd ${RAPIDS_DIR} && ./clone.sh

# Assume the build.sh script is present.
# (this is done automatically when using 'rapidsdevtool.sh buildDockerImage',
#  see rapidsdevtool.sh help for more details)
# Workaround so build.sh change is in docker image to allow testing build.sh
RUN cd ${RAPIDS_DIR} && \
    rm -rf rmm && \
    git clone -b add_build_script https://github.com/mluukkainen/rmm.git && \
    cd rmm && \
    git submodule update --init --remote --recursive && \
    source activate rapids && cd ${RAPIDS_DIR}/rmm && \
    ./build.sh && \
    git clean -xdff
RUN source activate rapids && cd ${RAPIDS_DIR} && \
    ./build.sh custrings && \
    cd custrings && git clean -xdff
RUN source activate rapids && cd ${RAPIDS_DIR}/cudf && \
    ./build.sh && \
    git clean -xdff
RUN source activate rapids && cd ${RAPIDS_DIR}/cuml && \
    ./build.sh && \
    git clean -xdff
RUN source activate rapids && cd ${RAPIDS_DIR}/cugraph && \
    ./build.sh && \
    git clean -xdff
RUN source activate rapids && cd ${RAPIDS_DIR} && \
    ./build.sh xgboost && \
    cd xgboost && git clean -xdff
RUN source activate rapids && cd ${RAPIDS_DIR} && \
    ./build.sh dask-xgboost && \
    cd dask-xgboost && git clean -xdff
RUN source activate rapids && cd ${RAPIDS_DIR} && \
    ./build.sh dask-cudf && \
    cd dask-cudf && git clean -xdff
RUN source activate rapids && cd ${RAPIDS_DIR} && \
    ./build.sh dask-cuda && \
    cd dask-cuda && git clean -xdff
RUN source activate rapids && cd ${RAPIDS_DIR} && \
    ./build.sh dask-cuml && \
    cd dask-cuml && git clean -xdff

#
# Change LD_LIBRARY_PATH to exclude /usr/local/cuda/* since
# numba.cuda cannot load that, and instead have it load
# /lib64/libcuda.so instead
#
ENV LD_LIBRARY_PATH="${GCC7_DIR}/lib64:${LD_LIBRARY_PATH_POSTBUILD}"

WORKDIR ${RAPIDS_DIR}/notebooks
# Jupyter notebook port
EXPOSE 8888
# Dask Scheduler Bokeh port
EXPOSE 8787
EXPOSE 8786

# Copy Dockerfile as late as possible to avoid invalidating cache for trivial changes
COPY Dockerfile.centos7 /Dockerfile.centos7

################################################################################
FROM rapids_ready AS base

# Retrieve values set prior to first FROM command for use below
ARG CUDA_VERSION
ARG CUDA_MAJORMINOR_VERSION
ARG PYTHON_VERSION
ARG RAPIDSAI_CONDA_LABEL
ARG RAPIDSAI_NIGHTLY_CONDA_LABEL
ARG NVIDIA_CONDA_LABEL
ARG IPYTHON_VERSION
ARG NUMBA_VERSION
ARG NUMPY_VERSION
ARG PANDAS_VERSION
ARG PYARROW_VERSION
ARG XGBOOST_CONDA_LABEL
ARG XGBOOST_VERSION
ARG RAPIDS_CONDA_VERSION_SPEC
ARG DASK_XGBOOST_CONDA_VERSION_SPEC

# Option: simply copy the conda env created in the "devel" stage.
# This is fast but does not test the conda packages for correctness during an
# install operation.
#COPY --from=devel /conda/envs/rapids /conda/envs/rapids
#COPY --from=devel /rapids/notebooks /rapids/notebooks

# Option: 'conda install' all RAPIDS packages.
# This ensures the RAPIDS conda packages install correctly and (should) only
# install the minimal set of packages needed, but relies on anaconda.org servers
# and can be slow.

# NOTE: use these mirrors for faster downloads
#       -c http://10.33.227.188:88/numba \
#       -c http://10.33.227.188:88/conda-forge \
RUN export CUDA_MAJOR=`echo $CUDA_VERSION | cut -d'.' -f1` && \
    export CUDA_MINOR=`echo $CUDA_VERSION | cut -d'.' -f2` && \
    conda create -n rapids python=${PYTHON_VERSION} && \
    conda install -n rapids -y \
      -c ${RAPIDSAI_CONDA_LABEL} \
      -c ${RAPIDSAI_NIGHTLY_CONDA_LABEL} \
      -c ${NVIDIA_CONDA_LABEL} \
      -c nvidia \
      -c ${XGBOOST_CONDA_LABEL} \
      -c numba \
      -c conda-forge \
      -c pytorch \
      -c defaults \
      cudatoolkit=${CUDA_MAJOR}.${CUDA_MINOR} \
      pytest \
      openblas \
      cudf=${RAPIDS_CONDA_VERSION_SPEC} \
      cuml=${RAPIDS_CONDA_VERSION_SPEC} \
      cugraph=${RAPIDS_CONDA_VERSION_SPEC} \
      xgboost=${XGBOOST_VERSION} \
      dask-xgboost=${DASK_XGBOOST_CONDA_VERSION_SPEC} \
      dask-cuda=${RAPIDS_CONDA_VERSION_SPEC} \
      dask-cudf=${RAPIDS_CONDA_VERSION_SPEC} \
      dask-cuml=${RAPIDS_CONDA_VERSION_SPEC} \
   && conda clean -a

# Copy Dockerfile as late as possible to avoid invalidating cache for trivial changes
COPY Dockerfile.centos7 /Dockerfile.centos7

################################################################################
FROM base AS runtime

# Retrieve values set prior to first FROM command for use below
ARG CUDA_VERSION
ARG CUDA_MAJORMINOR_VERSION
ARG RAPIDSAI_CONDA_LABEL
ARG RAPIDSAI_NIGHTLY_CONDA_LABEL
ARG NVIDIA_CONDA_LABEL
ARG IPYTHON_VERSION
ARG NUMBA_VERSION
ARG NUMPY_VERSION
ARG PANDAS_VERSION
ARG PYARROW_VERSION

# NOTE: use these mirrors for faster downloads
#       -c http://10.33.227.188:88/numba \
#       -c http://10.33.227.188:88/conda-forge \
RUN export CUDA_MAJOR=`echo $CUDA_VERSION | cut -d'.' -f1` && \
    export CUDA_MINOR=`echo $CUDA_VERSION | cut -d'.' -f2` && \
    conda install -n rapids -y \
      -c ${RAPIDSAI_CONDA_LABEL} \
      -c ${RAPIDSAI_NIGHTLY_CONDA_LABEL} \
      -c ${NVIDIA_CONDA_LABEL} \
      -c nvidia \
      -c numba \
      -c conda-forge \
      -c pytorch \
      -c defaults \
      cudatoolkit=${CUDA_MAJOR}.${CUDA_MINOR} \
      bokeh \
      ipython=${IPYTHON_VERSION} \
      jupyterlab \
      matplotlib \
      networkx \
      numba=${NUMBA_VERSION} \
      numpy=${NUMPY_VERSION} \
      pandas=${PANDAS_VERSION} \
      pyarrow=${PYARROW_VERSION} \
      scikit-learn \
      scipy \
      seaborn \
   && conda clean -a

# Add notebooks and test script
RUN cd ${RAPIDS_DIR} && ./clone.sh notebooks

WORKDIR /rapids/notebooks
# Jupyter notebook port
EXPOSE 8888
# Dask Scheduler Bokeh port
EXPOSE 8787
EXPOSE 8786

# Copy Dockerfile as late as possible to avoid invalidating cache for trivial changes
COPY Dockerfile.centos7 /Dockerfile.centos7
